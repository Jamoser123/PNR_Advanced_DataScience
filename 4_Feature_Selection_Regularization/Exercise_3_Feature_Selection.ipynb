{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3fba9c1",
   "metadata": {},
   "source": [
    "# **Excercise Sheet 3:** Feature Selection and Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b81ea8a",
   "metadata": {},
   "source": [
    "# Part A: Foundations & Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dfa83b",
   "metadata": {},
   "source": [
    "Before diving into coding and implementing feature selection and regularization techniques, it's important to understand the fundamental concepts and motivations behind these methods.\n",
    "\n",
    "Take a moment to reflect on these concepts yourself before seeking additional help from ChatGPT ðŸ˜‰ You're also encouraged to discuss these ideas with your classmates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aae83b9",
   "metadata": {},
   "source": [
    "## 1. General Concepts\n",
    "\n",
    "### a) Why do we need to do feature seelction or regularization when wanting to do a linear regression model with a high number of features?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb93de2",
   "metadata": {},
   "source": [
    "#### Your Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898f5f25",
   "metadata": {},
   "source": [
    "#### Solution:\n",
    "- Overfitting: the model may fit the training data too closely, capturing noise rather than the underlying pattern. Bad generalization to new data.\n",
    "- Computational Cost: More features lead to increased computational complexity, making the model slower to train and evaluate.\n",
    "- Interpretability: A model with too many features can be difficult to interpret.\n",
    "- Numerical issues with model fitting, not able to estimate the coefficients properly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04fd1a2",
   "metadata": {},
   "source": [
    "### b) What does feature selection mean and how does it differ from regularization?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395a7370",
   "metadata": {},
   "source": [
    "#### Your Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6641e5a6",
   "metadata": {},
   "source": [
    "#### Solution:\n",
    "- Feature selection: Drop some features from the model, based on some criteria (e.g. correlation with target variable, statistical tests, etc.). The model is trained only on the selected features.\n",
    "- Regularization: All features are still included in the model, but their impact is reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0a5f79",
   "metadata": {},
   "source": [
    "### c) Can we be confident that we select the correct variables in feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8a25f2",
   "metadata": {},
   "source": [
    "#### Your Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c39596d",
   "metadata": {},
   "source": [
    "#### Solution:\n",
    "- It depends, in general it's difficult.\n",
    "- One issue could be that with a lot of predictors, some of them might just relate to the target by chance, and we might select them wrongly.\n",
    "- Another issue is that with highly correlated predictors, we might select one of them, but not the other, even if both are important for the outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deee6031",
   "metadata": {},
   "source": [
    "# Part B: Coding & Visualization\n",
    "\n",
    "Now let's apply our knowledge of feature selection and regularization! We start with some imports needed.\n",
    "\n",
    "*Hint:* The functions imported from the Helper file, may help you in certain tasks, but you are not required to use them. You can also write your own code to achieve the same results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f707c3f",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "- We can maybe also ennumerate the subpoints of a task, that would make it easier to read instead of bullet points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42c1db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c78b43",
   "metadata": {},
   "source": [
    "## 2. Linear Regression with high-dimensional data\n",
    "\n",
    "- Load and inspec the dataset `data/todo.csv`\n",
    "- What types of predictors and outcomes are present in the dataset?\n",
    "- Plot pairplots of the first 5 variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd34ac3",
   "metadata": {},
   "source": [
    "- Split the dataset into training and test set (70%/30% split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9323cab1",
   "metadata": {},
   "source": [
    "- Perform a linear regression using first using all features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328eca3e",
   "metadata": {},
   "source": [
    "- Now perform a linear regression using only `insert` features. Compare the two models using the linear regression table (Todo figure out what that is)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fed3b36",
   "metadata": {},
   "source": [
    "- Calculate MSE and R2 for both models on the training data. What can you conclude?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be072745",
   "metadata": {},
   "source": [
    "- Now predict and calculate MSE and R2 for both models on the test data. Is there a difference? What can you conclude?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a73611",
   "metadata": {},
   "source": [
    "- Show a plot of the fitted regression lines for the test data. How is the overfitting of model 2 visible? What features? Using PCA? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d227ee77",
   "metadata": {},
   "source": [
    "## 3. PCA Regression\n",
    "\n",
    "- Load the dataset `data/todo.csv`\n",
    "- What types of predictors and outcomes are present in the dataset?\n",
    "- Plot pairplots of the first 5 variables\n",
    "\n",
    "- Note:\n",
    "Use a dataset with numerical features that results in singularity error when linear regression with all predictors is fitted, ie. when p>>n. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468788ab",
   "metadata": {},
   "source": [
    "- Perform a linear regression using all the features and print the regression tabble. What do you observe?\n",
    "\n",
    "Solution: All the coefficients and p-values should be NANs. See here for example: https://bookdown.org/staedler_n/highdimstats/multiple-linear-regression.html#overfitting  \n",
    "\n",
    "Issue is p>>n; not able to compute coefficients. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a054f8",
   "metadata": {},
   "source": [
    "- Perform PCA on the dataset. Is it important to scale the data before PCA? \n",
    "\n",
    "*Hint:* Check if the units of the data differs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60991bf9",
   "metadata": {},
   "source": [
    "- Plot the cumulative explained variance (or individual explained variance). How many are needed to explain 80% of the variance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8854cfb2",
   "metadata": {},
   "source": [
    "- Now let's compute the linear regression using enough principal components to explain 80% of the variance.\n",
    "\n",
    "*Hint:* if you did not solve the previous exercise, continue with 20 principal components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad78926",
   "metadata": {},
   "source": [
    "- Print the regression table. Are the coefficients interpretable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7494f3",
   "metadata": {},
   "source": [
    "## 4. Ridge and Lasso Regression\n",
    "\n",
    "- Load the dataset `data/todo.csv`\n",
    "- What types of predictors and outcomes are present in the dataset?\n",
    "- Plot pairplots of the first 5 variables\n",
    "\n",
    "- Note maybe reuse dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca80055",
   "metadata": {},
   "source": [
    "- Split dataset into training and test set (70%/30% split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169e184e",
   "metadata": {},
   "source": [
    "- Fit Ridge regression with different alphas (use the function) using training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453a65c0",
   "metadata": {},
   "source": [
    "- Show coefficient shrinkage for different alphas. What do you observe? Do you expect coefficients to be zero for some alphas?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3262278a",
   "metadata": {},
   "source": [
    "- Fit Lasso regression with different alphas (use the function). Using training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699d1114",
   "metadata": {},
   "source": [
    "- Show the coefficients for each alpha. How do they change with increasing alpha? Are features dropped?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4486c3a",
   "metadata": {},
   "source": [
    "- Compare all Models (linear regresion on features, linear regression on PCA, Ridge and Lasso) using MSE and R2 on the test data. Which model performs best?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc8140a",
   "metadata": {},
   "source": [
    "## 5. Cross-Validation\n",
    "\n",
    "Does it make sense to put this here? maybe to reinforce the concepts?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d440b35e",
   "metadata": {},
   "source": [
    "- What is the difference between train-test split and cross-validation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9dc708",
   "metadata": {},
   "source": [
    "#### Your Answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58daa303",
   "metadata": {},
   "source": [
    "#### Solution:\n",
    "In cross validation all data is used once as train or test. Usually used when not having a lot of data. Train-test split is used when you have a lot of data and you can afford to keep some data only for test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b298506c",
   "metadata": {},
   "source": [
    "- perform a cross-validation(5-folds) with the lasso model from last exercise. Report the MSE for all folds. Are they different to the MSE of the test set form the previous exercise?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4c22e0",
   "metadata": {},
   "source": [
    "- Finally we introduce a new concept which is common in clincal data science. \"Leave-One-Out Cross-Validation\" (LOOCV). In this method, we leave one sample out for testing and use the rest for training. This is repeated for each sample in the dataset. Implement this and compare the results to the 5-fold cross-validation. What do you observe?\n",
    "\n",
    "\n",
    "*Hint:* Give them a hint on how to implement this"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
